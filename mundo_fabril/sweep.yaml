program: train.py
name: sweep_ambo
method: bayes
metric:
  name: episodic_rewards
  goal: maximize
parameters:
  policy_type:
    values: ['MlpPolicy']
  learning_rate:
    distribution: uniform
    min: 0.00001
    max: 0.001
  batch_size:
    values: [32, 64, 128]
  buffer_size:
    values: [50000, 100000]
  exploration_fraction:
    distribution: uniform
    min: 0.1
    max: 0.5
  exploration_final_eps:
    distribution: uniform
    min: 0.01
    max: 0.1
  gamma:
    distribution: uniform
    min: 0.9
    max: 0.999
  train_freq:
    values: [4, 8, 16]
  target_update_interval:
    values: [500, 1000, 2000]
  total_timesteps:
    values: [10000, 20000, 30000]
